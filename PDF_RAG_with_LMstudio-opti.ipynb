{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa2b9045-0485-4252-8348-680b126b591a",
   "metadata": {},
   "source": [
    "Scientific Publications as PDFs, Text Extraction, Storage SQL database, Chunks, Embedding and Vectorization, Retrieval, GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f4f4c-7300-4cb9-8a96-31b4fec74b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not required, but can be usefull if a Cell need local proxy connection to Docker or LM Studio\n",
    "'''\n",
    "import os\n",
    "os.environ['http_proxy']=\"http://localhost:1238\"\n",
    "os.environ['https_proxy']=\"http://localhost:1238\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f32765-9ce2-4a03-b023-c99450f64562",
   "metadata": {},
   "source": [
    "## 1<sup>st</sup> Setting Up PDF Collection and DATABASE Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1370d05a-0efb-4826-998d-f9db3d87b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "%run assets/func_inputoutput.py\n",
    "# Setup paths\n",
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)\n",
    "# Define pdf file directory\n",
    "pdf_collection_path = 'PET_Methods'\n",
    "pdf_path = os.path.join(cwd, \"docs\", pdf_collection_path)\n",
    "# Define database directory\n",
    "base_name = 'PET_Methods.db'\n",
    "database_name = os.path.join(cwd, \"docs\", pdf_collection_path, base_name)\n",
    "# Create settings dictionary\n",
    "settings = {\n",
    "    'working_directory': cwd,\n",
    "    'pdf_collection_path': pdf_collection_path,\n",
    "    'pdf_path': pdf_path,\n",
    "    'base_name': base_name,\n",
    "    'database_name': database_name,\n",
    "    'additional': 'value1'  # \n",
    "}\n",
    "# Save settings to a file\n",
    "save_settings(settings)\n",
    "# Later on, load settings and unpack directly into variables\n",
    "working_directory, pdf_collection_path, pdf_path, base_name, database_name, remaining_settings = load_settings()\n",
    "# Print the loaded settings\n",
    "print(f'\\nworking_directory {working_directory}')\n",
    "print(f\"\\nPDF Collection Path: {pdf_collection_path}\")\n",
    "print(f\"\\npdf_path: {pdf_path}\")  \n",
    "print(f\"\\nbase_name: {base_name}\")  \n",
    "print(f\"\\ndatabase_name: {database_name}\")  \n",
    "print(f\"\\nRemaining Settings: {remaining_settings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db60f4-722f-4e8e-b152-b986941f29f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory, pdf_collection_path, pdf_path, base_name, database_name, remaining_settings = load_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f44a23-c9cd-43c5-be3d-24fe4ed99cc5",
   "metadata": {},
   "source": [
    "## Read PDF and Extract TEXT, Stores in a SQLite3 database (db): GROBID based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c70f1c-43c1-4c48-a20a-fdfa32042b39",
   "metadata": {},
   "source": [
    "# Instructions for Running GROBID Docker\n",
    "1. Download the small GROBID docker image and copy `config.json` into the Jupyter notebook working directory.\n",
    "2. Run local Docker:\n",
    "    - Start Docker for Windows.\n",
    "    - Use CMD.\n",
    "3. Execute the following command to run the docker container:\n",
    "    ```bash\n",
    "    docker run --rm --init --ulimit core=0 -p 8070:8070 lfoppiano/grobid:0.8.0\n",
    "    ```\n",
    "4. Check the running docker with [http://localhost:8070](http://localhost:8070) and ensure this matches the one in your `config.json`.\n",
    "5. path to the PDF collections and database are setted above   \n",
    "6. Choose to recreate the SQL (y/n) or just reload the current one.\n",
    "7. Note that processing 70 PDFs can take over 10 minutes.\n",
    "8. Wait for the console message: \"Finished\".\n",
    "9. If you encounter an XML error or some \"localhost\" mix up, ensure you stay connected with the docker by avoiding proxy configurations elsewhere.\n",
    "10. todo: add new pdfs to database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a4210-da75-415b-a13a-831f4a6714b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from grobid_client.grobid_client import GrobidClient\n",
    "import json\n",
    "import grobid_tei_xml\n",
    "\n",
    "\n",
    "\n",
    "class GrobidAuthor:\n",
    "    def __init__(self, full_name):\n",
    "        self.full_name = full_name\n",
    "\n",
    "class GrobidBiblio:\n",
    "    def __init__(self, index, authors, title, date, volume, pages, issue, journal, doi):\n",
    "        self.index = index\n",
    "        self.authors = authors\n",
    "        self.title = title\n",
    "        self.date = date\n",
    "        self.volume = volume\n",
    "        self.pages = pages\n",
    "        self.issue = issue\n",
    "        self.journal = journal\n",
    "        self.doi = doi\n",
    "\n",
    "def extract_bibliographic_details(biblios, print_choice=False):\n",
    "    for biblio in biblios:\n",
    "        if print_choice:\n",
    "            print(\"Index\", biblio.index, \"| Title:\", biblio.title)\n",
    "            print(\"Authors:\")\n",
    "            for author in biblio.authors:\n",
    "                print(\"-\", author.full_name)\n",
    "\n",
    "            print(\"Date:\", biblio.date)\n",
    "            print(\"Volume:\", biblio.volume)\n",
    "            print(\"Pages:\", biblio.pages)\n",
    "            # print(\"Issue:\", biblio.issue)\n",
    "            print(\"Journal:\", biblio.journal)\n",
    "            print(\"Doi:\", biblio.doi)\n",
    "            print()\n",
    "        else:\n",
    "            i=1# Add any other logic you want to perform when print_choice is False\n",
    "            pass\n",
    "    ref_list = '*'.join([\n",
    "        f\" * Index: {biblio.index} | Title: {biblio.title} | Authors: {', '.join([author.full_name for author in biblio.authors])} | Date: {biblio.date} | Volume: {biblio.volume} | Pages: {biblio.pages} | Journal: {biblio.journal} | Doi: {biblio.doi}\\|\"\n",
    "        for biblio in biblios\n",
    "    ])\n",
    "    return ref_list\n",
    "    \n",
    "    \n",
    "client = GrobidClient(config_path=\"config.json\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\ndatabase_pathname\",database_name)\n",
    "\n",
    "\n",
    "\n",
    "service_name = \"processFulltextDocument\"\n",
    "\n",
    "# Check if the database file exists\n",
    "if os.path.exists(database_name):\n",
    "    while True:\n",
    "        choice = input(\"\\nThe database file already exists. Do you want to create a new one? (y/n): \")\n",
    "        if choice.lower() == 'y':\n",
    "            # Close the connection to the database if it is open\n",
    "            if 'conn' in locals():\n",
    "                conn.close()\n",
    "\n",
    "            # Delete the existing database file\n",
    "            conn = None  # Reset conn variable\n",
    "            os.remove(database_name)\n",
    "            break\n",
    "        elif choice.lower() == 'n':\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice! Please enter 'y' or 'n'.\")\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(database_name)\n",
    "# Create the table if it doesn't exist\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "result = cursor.fetchone()\n",
    "\n",
    "if result is None:\n",
    "    table_name = \"your_table_name\"  # Provide a table name of your choice\n",
    "    cursor.execute('''CREATE TABLE {table_name}\n",
    "                    (ID INTEGER PRIMARY KEY,\n",
    "                    Title TEXT,\n",
    "                    Authors TEXT,\n",
    "                    DOI TEXT,\n",
    "                    Citations INTEGER,\n",
    "                    Abstract TEXT,\n",
    "                    Body TEXT,\n",
    "                    Refs TEXT)'''.format(table_name=table_name))\n",
    "else:\n",
    "    table_name = result[0]\n",
    "    \n",
    "# Retrieve the maximum ID value from the table\n",
    "cursor.execute(\"SELECT MAX(ID) FROM {table_name}\".format(table_name=table_name))\n",
    "max_id = cursor.fetchone()[0]\n",
    "# Increment the ID value by one\n",
    "id_key = max_id + 1 if max_id is not None else 1\n",
    "\n",
    "\n",
    "if choice.lower() == 'y':\n",
    "    # Loop through the files in the directory\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            print(f\"filename: {filename}\")\n",
    "            file_path = os.path.join(path, filename)\n",
    "\n",
    "            pdf_file, status, text = client.process_pdf(service_name, \n",
    "                                     file_path, \n",
    "                                     generateIDs=True, \n",
    "                                     consolidate_header=True, \n",
    "                                     consolidate_citations=True, \n",
    "                                     include_raw_citations=True, \n",
    "                                     include_raw_affiliations=True, \n",
    "                                     tei_coordinates=True,                          \n",
    "                                     segment_sentences=True)\n",
    "\n",
    "\n",
    "            grobid_biblios=grobid_tei_xml.parse_citation_list_xml(text)\n",
    "            # Extract metadat and text and print the bibliographic details\n",
    "            ref_list=extract_bibliographic_details(grobid_biblios, print_choice=False)\n",
    "\n",
    "            doc = grobid_tei_xml.parse_document_xml(text)\n",
    "            title = doc.header.title\n",
    "            authors = ';'.join([a.full_name for a in doc.header.authors])\n",
    "            doi = str(doc.header.doi)\n",
    "            citations = str(len(doc.citations))\n",
    "            abstract = doc.abstract\n",
    "            body = doc.body\n",
    "\n",
    "            #----------------------------------------\n",
    "            print(f\"id_key: {id_key}\")\n",
    "            # Insert the information into the database\n",
    "            cursor.execute('''\n",
    "                INSERT INTO {table_name} (ID, Title, Authors, DOI, Citations, Abstract, Body, Refs)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            '''.format(table_name=table_name), (id_key, title, authors, doi, citations, abstract, body, ref_list))\n",
    "\n",
    "            # Commit the changes to the database\n",
    "            conn.commit()\n",
    "            # Increment the ID key for the next iteration\n",
    "            id_key += 1\n",
    "\n",
    "            # Retrieve the count of records from the table\n",
    "            cursor.execute(\"SELECT COUNT(*) FROM {table_name}\".format(table_name=table_name))\n",
    "            count = cursor.fetchone()[0]\n",
    "            print(\"record loop:\", count)\n",
    "elif choice.lower() == 'n':\n",
    "    print(\"\\n\\nActive database_pathname\", database_name)\n",
    "else:\n",
    "    print(\"Invalid choice! Please enter 'y' or 'n'.\")\n",
    "    \n",
    "# Retrieve the count of records from the table\n",
    "cursor.execute(\"SELECT COUNT(*) FROM {table_name}\".format(table_name=table_name))\n",
    "count = cursor.fetchone()[0]\n",
    "print(\"Total records:\", count)        \n",
    "# Close the connection\n",
    "conn.close()\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b3b4f3-ca02-4fcd-b653-133fd323d9be",
   "metadata": {},
   "source": [
    "# Check records of SQL database: \n",
    "### Can also be used alone without Docker, once SQL database was created\n",
    " * if start from here, then run settings in second cell at start \n",
    " * database\n",
    "    * base_name='sample.db'\n",
    "    * database_name=os.path.join(cwd, \"docs\", pdf_collection_path, base_name) #database\n",
    " * Enter the record number or 'q' to quit: After: Enter 'n' for next choice or 'q' for quitEnter the record number or 'q' to quit: After: Enter 'n' for next choice or 'q' for quit# Check of SQL database: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d1fe81-56f8-4dde-b286-2e26a7f22822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "# --- Database Connection ---\n",
    "try:\n",
    "    conn = sqlite3.connect(database_name)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    if not tables:\n",
    "        raise ValueError(\"No tables found in the database.\")\n",
    "    table_name = tables[0][0]\n",
    "\n",
    "    # --- Check if the table has any rows ---\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "    row_count = cursor.fetchone()[0]\n",
    "    if row_count == 0:\n",
    "        raise ValueError(f\"Table '{table_name}' is empty.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Database Error: {e}\")\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "user_input = input(\"dashboard: 'n' : 'y'\")\n",
    "\n",
    "if user_input.lower() == 'y':\n",
    "    \n",
    "    # --- Record Selection ---\n",
    "    record_ids_select = pn.widgets.Select(\n",
    "        name='Record ID', \n",
    "        sizing_mode='stretch_width',\n",
    "        styles={\n",
    "            'background-color': 'white',  # White background\n",
    "            'color': 'black',  # Black text\n",
    "            'border-color': '#555'\n",
    "        }\n",
    "    )\n",
    "\n",
    "    def populate_record_ids():\n",
    "        try:\n",
    "            cursor.execute(f\"SELECT rowid, body FROM {table_name}\")\n",
    "            records = cursor.fetchall()\n",
    "            if records:\n",
    "                # Create options with a truncated preview and full record ID\n",
    "                record_options = {}\n",
    "                for row in records:\n",
    "                    # Truncate body for display, but keep full rowid\n",
    "                    preview = row[1][:100] + '...' if len(row[1]) > 100 else row[1]\n",
    "                    record_options[f\"ID {row[0]}: {preview}\"] = row[0]\n",
    "\n",
    "                record_ids_select.options = record_options\n",
    "                # Set initial value to the first record\n",
    "                record_ids_select.value = list(record_options.values())[0]\n",
    "            else:\n",
    "                print(\"No records found.\")\n",
    "                record_ids_select.options = []\n",
    "                output_area.value = \"No records found in the table.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error populating record IDs: {e}\")\n",
    "            output_area.value = f\"Error: {e}\"\n",
    "\n",
    "    # --- Output Area with full screen height and dark theme ---\n",
    "    output_area = pn.widgets.TextAreaInput(\n",
    "        value=\"\", \n",
    "        sizing_mode='stretch_width',  # Stretch to full width\n",
    "        height=600,  # Increased height to 600 pixels\n",
    "        styles={\n",
    "            'background-color': 'white', #'#1a1a1a',  # Very dark background\n",
    "            'color': '#e0e0e0',  # Light gray text for better readability\n",
    "            'font-family': 'monospace',\n",
    "            'font-size': '14px',\n",
    "            'border-color': '#555',\n",
    "            'padding': '10px'\n",
    "        },\n",
    "        disabled=True\n",
    "    )\n",
    "\n",
    "    @pn.depends(record_ids_select.param.value, watch=True)\n",
    "    def update_output(record_id):\n",
    "        if record_id is None:\n",
    "            output_area.value = \"No record selected or table is empty.\"\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            cursor.execute(f\"SELECT body FROM {table_name} WHERE rowid = ?\", (record_id,))\n",
    "            record_body = cursor.fetchone()\n",
    "\n",
    "            if record_body:\n",
    "                # Ensure text is fully visible\n",
    "                output_area.value = str(record_body[0])\n",
    "            else:\n",
    "                output_area.value = f\"Record with ID {record_id} not found.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            output_area.value = f\"Error retrieving record: {e}\"\n",
    "\n",
    "    # Initial population and update\n",
    "    populate_record_ids()\n",
    "    update_output(record_ids_select.value)\n",
    "\n",
    "    # --- Dashboard Layout ---\n",
    "    dashboard_layout = pn.Column(\n",
    "        pn.pane.Markdown(\n",
    "            \"## Record Viewer\", \n",
    "            styles={'color': 'white', 'background-color': '#222'}\n",
    "        ),\n",
    "        record_ids_select,\n",
    "        output_area,\n",
    "        sizing_mode='stretch_width',\n",
    "        styles={\n",
    "            'background-color': '#222',  # Dark background for the entire layout\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Add global dark theme CSS\n",
    "    pn.config.raw_css.append(\"\"\"\n",
    "        body {\n",
    "            background-color: #222 !important;\n",
    "            color: #e0e0e0 !important;\n",
    "        }\n",
    "        .bk-root {\n",
    "            background-color: #222;\n",
    "        }\n",
    "        .bk-input-container {\n",
    "            background-color: #333 !important;\n",
    "        }\n",
    "    \"\"\")\n",
    "\n",
    "    # Display the dashboard\n",
    "    dashboard = pn.panel(dashboard_layout)\n",
    "    dashboard.show()\n",
    "    \n",
    "# Close the connection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c285f4-fed9-45fd-8fa0-2085191f07e4",
   "metadata": {},
   "source": [
    "# Running LM Studio and Creating or Loading Vector Database with or without previous steps\n",
    "based on: Chroma version: 0.5.0 | Langchain version: 0.2.3\n",
    "\n",
    "1. Start LM Studio 0.2.27.\n",
    "2. Activate the Local Server Tab (\" <-> \").\n",
    "3. Select a model, e.g., \"Meta-Llama-3-8B-Instruct-Q8_0.gguf\".\n",
    "    - Choose the preset \"Llama3\".\n",
    "4. Choose a server port that does not conflict with the docker port.\n",
    "5. Load the \"Embedding Model\", e.g., \"nomic embed text v1 5 Q8_0.gguf\".\n",
    "    - Models were previously downloaded manually from Huggingface/Models/.\n",
    "6. Press \"Start Server\".\n",
    "7. Define if required the following paths in line 80-81:\n",
    "    ```python\n",
    "    \n",
    "    user_path = os.path.join(os.getcwd(), \"docs\", pdf_collection_path, \"sample\")\n",
    "    temp_dir = os.path.join(os.getcwd(), \"docs\", \"temp\")\n",
    "    \n",
    "    ```\n",
    "8. Run the cell:\n",
    "    - If there is an error indicating the base is in use, ensure the path is correct and start from the cell \"Check SQL Database\" after restarting the kernel.\n",
    "9. If there is a connection error to LM, remove any other open proxy or browser proxy settings in \"Settings\" in browser proxy settings, restart the kernel, and start from \"Check SQL Database\", or disable warnings and proxy settings in line 130 \n",
    "10. After `embed_and_chunk` with adding metadate, creating the vector database, set mode in line 186 to `load` or ``append``.\n",
    "11. Also chose \"new_vectordbnew_vectordb= False or True\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd54cdd8-1dad-46df-9dd5-81b0884a2184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thomas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings loaded from settings.json.\n",
      "\n",
      "path and name settings from above were loaded\n",
      "\n",
      "  There are additional settings that could be added:\n",
      "  additional: value1\n",
      "\n",
      " Finished reading and adding Metadata to database e:\\users\\behnisch\\python\\envs\\GPT\\openai-quickstart-node-master\\PDF_screen\\Langchain\\LangChain-Chat-with-Your-Data-main\\docs\\PET_Methods\\PET_Methods.db records \n",
      "\n",
      "creates texts, embedding_dict and verctordb if mode is \"load\": Current Mode: load\n",
      "mode load | force_overwrite True\n",
      "Loading vector database from e:\\users\\behnisch\\python\\envs\\GPT\\openai-quickstart-node-master\\PDF_screen\\Langchain\\LangChain-Chat-with-Your-Data-main\\docs\\temp...\n",
      "Vector database loaded in 1.22 seconds.\n",
      "Number of original documents: 17 | chunks 332\n",
      "\n",
      "finished e:\\users\\behnisch\\python\\envs\\GPT\\openai-quickstart-node-master\\PDF_screen\\Langchain\\LangChain-Chat-with-Your-Data-main\\docs\\temp \n",
      " chunks:  332\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Import here\n",
    "import sqlite3\n",
    "\n",
    "%run assets/func_inputoutput.py\n",
    "\n",
    "class CustomEmbedding2:  # If you MUST keep this, initialize client here\n",
    "    def __init__(self, client):  # Pass client to the constructor\n",
    "        self.client = client  # Store the client\n",
    "        self.embeddings = []\n",
    "\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        embeddings = [self.get_embedding(text) for text in texts] # use self.get_embedding\n",
    "        self.embeddings = embeddings\n",
    "        return embeddings\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        embedding = self.get_embedding(text)  # Use self.get_embedding\n",
    "        self.embeddings = [embedding]\n",
    "        return embedding\n",
    "\n",
    "    def get_embedding(self, text, model=\"TheBloke/nomic-embed-text\"): # make this a method of the class\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        return self.client.embeddings.create(input=[text], model=model).data[0].embedding # Use self.client\n",
    "\n",
    "\n",
    "\n",
    "def embed_and_chunk2(docs, embedding, chunk_size=2000, chunk_overlap=200):\n",
    "    \"\"\"Embeds and chunks a list of Documents, returning a tuple (texts, embeddings).\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    texts = text_splitter.split_documents(docs)\n",
    "\n",
    "    embeddings = embedding.embed_documents([doc.page_content for doc in texts])\n",
    "\n",
    "    # Store embeddings in a dictionary, keyed by document chunk ID or index\n",
    "    embedding_dict = {i: emb for i, emb in enumerate(embeddings)}  # Or use some unique ID from doc.metadata\n",
    "\n",
    "    return texts, embedding_dict\n",
    "\n",
    "def embed_and_chunk(docs, embedding, chunk_size=2000, chunk_overlap=200):\n",
    "    \"\"\"Embeds and chunks a list of Documents.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    texts = text_splitter.split_documents(docs)\n",
    "\n",
    "    embeddings = embedding.embed_documents([doc.page_content for doc in texts])\n",
    "\n",
    "\n",
    "    embedding_dict = {i: emb for i, emb in enumerate(embeddings)}  # Still useful for efficient embedding lookup\n",
    "\n",
    "\n",
    "    # IMPORTANT: Add \"doc_id\" to each chunk's metadata:\n",
    "    for i, text in enumerate(texts):\n",
    "        text.metadata['doc_id'] = text.metadata['ID'] # Or whatever unique ID you are using from SQLite\n",
    "\n",
    "\n",
    "        text.metadata['chunk_id'] = i  # It's often helpful to have a unique chunk ID as well\n",
    "\n",
    "    return texts, embedding_dict\n",
    "\n",
    "def create_vectordb(texts, embedding, user_path=None, persist_directory=None, mode=\"create\", force_overwrite=True):\n",
    "    \"\"\"Creates, loads, or appends to a vector database.\"\"\"\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    if mode == \"create\":  # Create a new database (overwrites if exists)\n",
    "        if persist_directory is None:\n",
    "            if user_path:\n",
    "                persist_directory = os.path.join(cwd, user_path, 'chroma_db')\n",
    "            else:\n",
    "                persist_directory = os.path.join(cwd,'chroma_db')\n",
    "                raise ValueError(f\"persist_directory or user_path must be provided when creating, now used {persist_directory}\")\n",
    "                \n",
    "        if os.path.exists(persist_directory): # Crucial check for empty directory\n",
    "            if os.listdir(persist_directory): # Check if the directory is NOT empty\n",
    "                if force_overwrite:  # Only remove if force_overwrite is True and not empty\n",
    "                    shutil.rmtree(persist_directory)\n",
    "                else:\n",
    "                    raise FileExistsError(f\"Vector database directory '{persist_directory}' is not empty. Use mode='append' or set force_overwrite=True to overwrite.\")\n",
    "            else: # Directory exists but empty\n",
    "                shutil.rmtree(persist_directory) # clean since old chroma files might be in\n",
    "\n",
    "        print(\"Creating a new vector database...\")  # More informative message\n",
    "        start_time = time.time()\n",
    "        vectordb = Chroma.from_documents(texts, embedding, persist_directory=persist_directory)\n",
    "        end_time = time.time()\n",
    "        print(f\"New vector database created in {end_time - start_time:.2f} seconds. Directory: {persist_directory}\")\n",
    "\n",
    "\n",
    "\n",
    "    elif mode == \"load\":  # Load existing database\n",
    "        if persist_directory is None:\n",
    "            if user_path:\n",
    "                persist_directory = os.path.join(cwd, user_path, 'chroma_db')\n",
    "            else:\n",
    "                raise ValueError(\"persist_directory or user_path must be provided when loading\")\n",
    "\n",
    "        if not os.path.exists(persist_directory):\n",
    "            raise FileNotFoundError(f\"Vector database not found: {persist_directory}\") # Raise exception\n",
    "\n",
    "        print(f\"Loading vector database from {persist_directory}...\")\n",
    "        start_time = time.time()\n",
    "        vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "        end_time = time.time()\n",
    "        print(f\"Vector database loaded in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "\n",
    "    elif mode == \"append\":\n",
    "        if persist_directory is None:\n",
    "            if user_path:\n",
    "                persist_directory = os.path.join(cwd, user_path, 'chroma_db')\n",
    "            else:\n",
    "                raise ValueError(\"persist_directory or user_path must be provided when appending\")\n",
    "\n",
    "\n",
    "        if not os.path.exists(persist_directory):\n",
    "            raise FileNotFoundError(f\"Vector database not found: {persist_directory}\") # Raise exception\n",
    "\n",
    "        print(f\"Appending to vector database at {persist_directory}...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n",
    "        vectordb.add_documents(texts)\n",
    "        end_time = time.time()\n",
    "        print(f\"Documents appended in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid mode: {mode}. Choose 'create', 'load', or 'append'.\")\n",
    "\n",
    "    return vectordb, persist_directory\n",
    "\n",
    "import os\n",
    "import urllib3\n",
    "\n",
    "# Disable warnings and proxy settings\n",
    "os.environ['NO_PROXY'] = 'localhost,127.0.0.1'\n",
    "urllib3.disable_warnings()\n",
    "urllib3.util.connection.is_connection_dropped = lambda conn: False\n",
    "\n",
    "# Configure requests to ignore proxies\n",
    "import requests\n",
    "requests.Session().trust_env = False\n",
    "\n",
    "working_directory, pdf_collection_path, pdf_path, base_name, database_name,_ = load_settings()\n",
    "\n",
    "user_path = os.path.join(os.getcwd(), \"docs\", pdf_collection_path, \"sample\")\n",
    "temp_dir = os.path.join(os.getcwd(), \"docs\", \"temp\")\n",
    "\n",
    "desired_chunk_size = 2000\n",
    "chunk_overlap = 450\n",
    "\n",
    "persist_directory=temp_dir\n",
    "\n",
    "client = OpenAI(base_url=\"http://localhost:1238/v1\", api_key=\"lm-studio\") # Important: Initialize client before embedding\n",
    "embedding = CustomEmbedding2(client=client)\n",
    "\n",
    "\n",
    "# Database connection and document loading:\n",
    "conn = sqlite3.connect(database_name)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "if not tables:\n",
    "    raise ValueError(\"No tables found in the database.\")\n",
    "table_name = tables[0][0]\n",
    "\n",
    "cursor.execute(f\"SELECT ID, Title, Abstract, Body FROM {table_name}\")  # Simplified query (removed Authors, DOI if not needed)\n",
    "#cursor.execute(\"SELECT ID, Title, Authors, DOI, Abstract, Body FROM {table_name}\".format(table_name=table_name))\n",
    "results = cursor.fetchall()\n",
    "\n",
    "num_original_docs = 0  # Initialize counter\n",
    "docs = []  # List to store the Document objects *before* chunking\n",
    "\n",
    "for result in results:\n",
    "    record_id, title, abstract, body = result\n",
    "    \n",
    "    #print(f\"Record_id {record_id} | title {title}\")\n",
    "    num_original_docs += 1  # Increment counter\n",
    "    if abstract is None:\n",
    "        abstract = \"\"\n",
    "    if body is None:\n",
    "        body = \"\"\n",
    "\n",
    "    combined_text = abstract + \" \" + body\n",
    "    doc = Document(page_content=combined_text, metadata={'ID': record_id, 'Title': title})\n",
    "    docs.append(doc)  # Add the whole document\n",
    "print(f\"\\n Finished reading and adding Metadata to database {database_name} records \")\n",
    "\n",
    "conn.close()\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "mode=\"load\"\n",
    "force_overwrite=True\n",
    "\n",
    "\n",
    "print(f'\\ncreates texts, embedding_dict and verctordb if mode is \"load\": Current Mode: {mode}')\n",
    "texts, embedding_dict = embed_and_chunk(docs, embedding, chunk_size=desired_chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "\n",
    "print(f'mode {mode} | force_overwrite {force_overwrite}')\n",
    "vectordb, _ = create_vectordb(texts, embedding, user_path=user_path, persist_directory=persist_directory, mode=mode, force_overwrite=force_overwrite)  # Pass force_overwrite\n",
    "\n",
    "#vectordb.persist()  # Persist the database and release locks\n",
    "print(f\"Number of original documents: {num_original_docs} | chunks {vectordb._collection.count()}\")  # Now you have the original count\n",
    "\n",
    "\n",
    "print(\"\\nfinished\", persist_directory, \"\\n chunks: \", len(vectordb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf96eae-58ef-489b-9087-3e58c36ad5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip=True\n",
    "if not skip:\n",
    "    # To retrieve and display chunks for a specific document ID:\n",
    "    doc_id_to_retrieve = 14  # Example: Retrieve chunks for document with ID 1\n",
    "\n",
    "    # Method 1: Filter chunks after retrieval (simpler if your vector database doesn't support metadata filtering during search)\n",
    "    chunks = vectordb.similarity_search(\"your query\", k=100) # retrieve a larger number of chunks than needed\n",
    "    #relevant_chunks = [c for c in chunks if c.metadata.get('doc_id') == doc_id_to_retrieve]\n",
    "\n",
    "\n",
    "    # Method 2: Filter during retrieval (if your vector database supports it â€“ more efficient):\n",
    "    relevant_chunks = vectordb.similarity_search(\"your query\", k=100, filter={\"doc_id\": doc_id_to_retrieve})  # This depends on vectordb capabilities\n",
    "\n",
    "\n",
    "    for chunk in relevant_chunks:\n",
    "        print(f\"Chunk ID: {chunk.metadata['chunk_id']}\")\n",
    "        print(f\"Document ID: {chunk.metadata['doc_id']}\")\n",
    "        print(chunk.page_content)\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ef748-65ed-442a-8b75-c4c5eb0448e6",
   "metadata": {},
   "source": [
    "# Required to Run: Alternative Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9229f8b-46a5-4dd8-9012-2706b695731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm  = OpenAI(base_url=\"http://localhost:1238/v1\", api_key=\"lm-studio\")\n",
    "#llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# we instantiated the retreiever above\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(), \n",
    "    llm=llm\n",
    ")\n",
    "# Set logging for the queries\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
    "\n",
    "#unique_docs = retriever_from_llm.get_relevant_documents(query=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8de174-2c68-487b-ba6c-316fb118ae95",
   "metadata": {},
   "source": [
    "# PDF retrieval with keeping metdata as citation with contents in text\n",
    "# PANEL DASHBOARD\n",
    "## 1st Based on  client.chat.completions.create  : \n",
    "    * Browser TAB\n",
    "    * Prompt Input\n",
    "    * Query\n",
    "    * Response\n",
    "    * Whole message sent to Model\n",
    "## Chose Retrieval: Standard or Multi (langChain): line 42\n",
    "    * retriever_from_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a78d20d8-c2c2-4346-9283-d5d4e2c7ef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thomas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.1.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 9;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/bootstrap5/js/bootstrap.bundle.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      Bokeh = root.Bokeh;\n",
       "      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      if (!reloading && (!bokeh_loaded || is_dev)) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.1.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/bootstrap5/js/bootstrap.bundle.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='c31dc005-1933-4e8c-b569-cf9ad640c1aa'>\n",
       "  <div id=\"f1fab8b1-048a-4b07-a804-8f4804327e5c\" data-root-id=\"c31dc005-1933-4e8c-b569-cf9ad640c1aa\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"e6930eb9-a771-4b45-9039-16571d04e1c2\":{\"version\":\"3.1.1\",\"title\":\"Bokeh Application\",\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}],\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"c31dc005-1933-4e8c-b569-cf9ad640c1aa\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"cf4a642f-b16e-4336-aac0-73fe3f449a93\",\"attributes\":{\"plot_id\":\"c31dc005-1933-4e8c-b569-cf9ad640c1aa\",\"comm_id\":\"55b8fa3ec1fa4d069df7539b66811f2c\",\"client_comm_id\":\"ee757613fe114e9abdce5f578deed329\"}}],\"callbacks\":{\"type\":\"map\"}}};\n",
       "  var render_items = [{\"docid\":\"e6930eb9-a771-4b45-9039-16571d04e1c2\",\"roots\":{\"c31dc005-1933-4e8c-b569-cf9ad640c1aa\":\"f1fab8b1-048a-4b07-a804-8f4804327e5c\"},\"root_ids\":[\"c31dc005-1933-4e8c-b569-cf9ad640c1aa\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  const is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version && !is_dev) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "c31dc005-1933-4e8c-b569-cf9ad640c1aa"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching server at http://localhost:51059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<panel.io.server.Server at 0x2435fbe6b80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this change original is above seems to wrok with correct template\n",
    "import panel as pn\n",
    "from openai import OpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "#from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "import re\n",
    "import time\n",
    "%run assets/func_inputoutput.py\n",
    "# Disable warnings and proxy settings\n",
    "os.environ['NO_PROXY'] = 'localhost,127.0.0.1'\n",
    "urllib3.disable_warnings()\n",
    "urllib3.util.connection.is_connection_dropped = lambda conn: False\n",
    "\n",
    "# Configure requests to ignore proxies\n",
    "import requests\n",
    "requests.Session().trust_env = False\n",
    "\n",
    "# Define the template for the prompt t1\n",
    "template1 = \"\"\"\n",
    "Use the following retrieved documents and the previous conversation to answer the query. Incorporate your own knowledge and reasoning as an AI assistant:\n",
    "Previous Conversation: {history}\n",
    "Query: {query}\n",
    "Retrieved Documents: {retrieved_docs}\n",
    "Answer:\n",
    "{answer}\n",
    "\"\"\"\n",
    "\n",
    "# Define the template for the prompt t2\n",
    "template2 = \"\"\"\n",
    "Use the following Retrieved Documents and the previous conversation to answer the query. Incorporate your own knowledge and reasoning as an AI assistant.  Keep the content together with document and chunk numbers at the end of sentences in brackets. If content from different documents is combined into a new sentence, place the document and chunk numbers at the end of the sentence, separated by semicolons.\n",
    "Previous Conversation: {history}\n",
    "Query: {query}\n",
    "Retrieved Documents: {retrieved_docs}\n",
    "Answer:\n",
    "{answer}\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "CRITICAL CITATION INSTRUCTIONS:\n",
    "1. MANDATORY: Cite the EXACT Document and Chunk number for EVERY piece of information retrieved from Retrieved Documents\n",
    "2. Format citations EXACTLY like this: \n",
    "   - Single source: \"(Document Number, Chunk Number)\"\n",
    "   - Multiple sources: \"(Document Number, Chunk Number; Document Number, Chunk Number)\"\n",
    "3. Place citations IMMEDIATELY after the relevant information, inside parentheses\n",
    "4. NEVER omit citations\n",
    "5. If rephrasing content, still include original source citation\n",
    "\n",
    "Use the following Retrieved Documents and the previous conversation to answer the query:\n",
    "\n",
    "Previous Conversation: {history}\n",
    "Query: {query}\n",
    "Retrieved Documents: {retrieved_docs}\n",
    "\n",
    "RESPONSE GUIDELINES:\n",
    "- Create a cohesive, well-structured paragraph\n",
    "- Ensure EVERY fact is explicitly cited\n",
    "- Maintain scientific rigor and precision\n",
    "- Include citations WITHOUT FAIL\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "# Create the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"history\", \"query\", \"retrieved_docs\", \"answer\"],  # Removed 'context'\n",
    "    template=template\n",
    ")\n",
    "\n",
    "\n",
    "history = []\n",
    "\n",
    "# Point to the local OpenAI server\n",
    "client = OpenAI(base_url=\"http://localhost:1238/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "\n",
    "which_retriever='Standard'\n",
    "#which_retriever='Standard'\n",
    "\n",
    "if which_retriever =='Multi':\n",
    "    retriever=retriever_from_llm\n",
    "else:\n",
    "    # Set up the vector retriever\n",
    "    retriever = vectordb.as_retriever()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Define a function to handle the user's input\n",
    "def handle_input2(vectordb, embedding, llm, retriever): # Pass as arguments\n",
    "    global is_first_run  # Access global variables\n",
    "    wrap_width = 100\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if is_first_run:\n",
    "        query = \"Hello, introduce yourself to someone opening this program for the first time. Be concise. Do not add citations in this message.\"\n",
    "        \n",
    "        similar_docs=[]        \n",
    "        output_box_retrievalTime.object = f\"Processing Retrieval {is_first_run}\"\n",
    "    else:\n",
    "        #output_box_retrievalTime.object = f\"Processing Retrieval: {is_first_run}\"\n",
    "        output_box_gpt_responseTime = f\"Waiting for GPT\"\n",
    "        #start_timere = time.time()\n",
    "        query = input_box.value.strip()\n",
    "\n",
    "    #history.append({\"role\": \"user\", \"content\": query)# + \" Database content: [\" + some_context + \"]\"})\n",
    "\n",
    "    if query:\n",
    "        managed_history = manage_conversation_history(history)\n",
    "        #vector_db_query = \"Image normalization methods for analyzing brain metabolism in different brain regions.\"  # Use the concise prompt\n",
    "        \n",
    "        selected_method ='combined' #'keywords' #llm, combined\n",
    "        \n",
    "        retrieved_docs = \"\"        \n",
    "        retriever = DocumentRetriever(vectordb)\n",
    "        retrieved_docs, used_query, method_retquery = retriever.retrieve_documents(query, is_first_run, k=4, method=selected_method)\n",
    "                \n",
    "        used_query=f\"**Used Retrieval Query:**  \\n {used_query}\\n\"        \n",
    "        \n",
    "        output_box3.object=used_query\n",
    "\n",
    "        prompt = prompt_template.format(\n",
    "            history=managed_history,#history,\n",
    "            query=query,\n",
    "            retrieved_docs=retrieved_docs,  # Use retrieved_text here\n",
    "            answer=\"\"\n",
    "        )\n",
    "        output_box2.object = prompt\n",
    "        \n",
    "        end_timere = time.time()\n",
    "        # Calculate the elapsed time\n",
    "        elapsed_timere = end_timere - start_time\n",
    "        \n",
    "        retrieved_tokens=word_count(retrieved_docs)\n",
    "        output_box_retrievalTime.object = f\"Time for Retrieval with: {elapsed_timere:.2f} seconds | retrieved_docs_length {retrieved_tokens} | selected_method {selected_method}\\n | {method_retquery}\"\n",
    "       \n",
    "\n",
    "        # Display formatted messages in output box\n",
    "        messages = managed_history + [{\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"\"\"You are a precise scientific document analysis AI. \n",
    "            ABSOLUTE REQUIREMENTS:\n",
    "            - Cite sources for EVERY piece of information recieved from Retrieved_Docs\n",
    "            - Use EXACT Document and Chunk citation Numbers indicated in front of each text paragraphs in Retrieved_Docs\n",
    "            - Never generate unsourced claims\n",
    "            - If taken a citation from text like (Lee et al.,) list at the end, but do not invent title or other data\n",
    "            - Be scientifically accurate and rigorous and write with excelent transfer sentences in the Sytle of Eric Kandel\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "            ]       \n",
    "        \n",
    " \n",
    "                    \n",
    "        \n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"LLMA/Meta-Llama-3-8B\",  # Correct model name/path here!\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            stream=True,\n",
    "        )\n",
    "\n",
    "        new_message = {\"role\": \"assistant\", \"content\": \"\"}\n",
    "        full_response = \"\"\n",
    "        for chunk in completion:\n",
    "            if chunk.choices[0].delta.content:\n",
    "                new_message[\"content\"] += chunk.choices[0].delta.content\n",
    "                full_response += chunk.choices[0].delta.content\n",
    "\n",
    "\n",
    "        # Combine the summary and LLM response in the displayed output\n",
    "        final_output = f\"Final Answer:\\n{full_response}\"  # Adjust formatting as needed\n",
    "        formatted_text = f\"**Query:**  \\n{query}\\n\\n**Final Answer (with Summaries):**  \\n{final_output}\"\n",
    "        #not tested: formatted_text = f\"<div style='white-space: normal; word-wrap: break-word; overflow-wrap: break-word; font-family: Arial, sans-serif; font-size: 12px;'>\\\n",
    "        #                **Query:**<br>{query}<br><br>**Final Answer (with Summaries):**<br>{final_output}</div>\"\n",
    "        output_box.object = formatted_text  # Update output box  \n",
    "        \n",
    "        message_tokens=word_count(messages)\n",
    "        history_tokens=word_count(managed_history) \n",
    "        \n",
    "        history.append(new_message)   \n",
    "        \n",
    "        input_box.value = \"\"        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        output_box_responseTime.object = f\"Time taken for Model: {elapsed_time:.2f} seconds | message_length: {message_tokens} | history {history_tokens}\"\n",
    "        \n",
    "    is_first_run = False\n",
    "\n",
    "\n",
    "# Define a function to handle user input changes\n",
    "def handle_input_change(event):\n",
    "    handle_input2(vectordb, embedding, llm, retriever)\n",
    "\n",
    "# Apply debounce to input handling\n",
    "@debounce(wait=0.1)  # 500 ms delay\n",
    "def handle_input_debounced(event):\n",
    "    handle_input2(vectordb, embedding, llm, retriever)\n",
    "\n",
    "    \n",
    "# Load the Panel extension\n",
    "pn.extension(\n",
    "    design='bootstrap',\n",
    "    theme='default', #'dark'\n",
    "    sizing_mode='stretch_both'  # Ensures full-width rendering\n",
    ")\n",
    "\n",
    "# Improved Input Box Styling\n",
    "input_box = pn.widgets.TextAreaInput(\n",
    "    width=None, \n",
    "    height=300, \n",
    "    placeholder=\"Enter your query here...\",\n",
    "    styles={\n",
    "        'color': '#333333',\n",
    "        'background-color': '#ffffff',\n",
    "        'border': '1px solid #cccccc',\n",
    "        'border-radius': '6px',\n",
    "        'padding': '10px',\n",
    "        'font-family': 'Arial, sans-serif',\n",
    "        'font-size': '16px',\n",
    "        'line-height': '1.5',  # Consistent line height\n",
    "        'overflow-y': 'auto',\n",
    "        'margin-top': '20px',\n",
    "        'box-sizing': 'border-box',  # Include padding in width calculation\n",
    "        'width': '100%', # Ensure the box stretches to the full width of its container\n",
    "        'resize': 'none',  # Prevent manual resizing\n",
    "        'word-wrap': 'break-word',\n",
    "        'word-break': 'break-word',\n",
    "        'white-space': 'pre-wrap'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Loading Indicator Styling\n",
    "loading_indicator = pn.indicators.LoadingSpinner(\n",
    "    value=False, \n",
    "    width=20, \n",
    "    height=20,\n",
    "    styles={\n",
    "        'margin-left': '10px',\n",
    "        'color': '#007bff'  # Bootstrap primary color\n",
    "    }\n",
    ")\n",
    "\n",
    "output_box = pn.pane.Markdown(\n",
    "    width=None,\n",
    "    height=300,\n",
    "    styles={\n",
    "        'width': '100%',\n",
    "        'color': '#212529',\n",
    "        'background-color': '#f0f2f4',\n",
    "        'border': '1px solid #dee2e6',\n",
    "        'border-radius': '6px',\n",
    "        'font-size': '14px',\n",
    "        'font-weight': '400',\n",
    "        'font-family': 'Arial, sans-serif',\n",
    "        'line-height': '1.6',\n",
    "        'padding': '10px',\n",
    "        'box-sizing': 'border-box',\n",
    "        \n",
    "        # Text wrapping properties\n",
    "        'word-wrap': 'break-word',\n",
    "        'word-break': 'break-word',\n",
    "        'overflow-wrap': 'break-word',\n",
    "        'white-space': 'normal',\n",
    "        'text-align': 'left',\n",
    "        'hyphens': 'auto',\n",
    "        'overflow-y': 'auto',\n",
    "        \n",
    "        'display': 'block',\n",
    "        'max-width': '100%'\n",
    "    }\n",
    ")\n",
    "\n",
    "output_box3 = pn.pane.HTML(\n",
    "    width=None,\n",
    "    height=100,\n",
    "    styles={\n",
    "        'color': '#212529',\n",
    "        'background-color': '#f0f2f4',\n",
    "        'border': '1px solid #dee2e6',\n",
    "        'border-radius': '6px',\n",
    "        'font-size': '18px',\n",
    "        'font-weight': '400',\n",
    "        'font-family': 'Arial, sans-serif',\n",
    "        'line-height': '1.6',\n",
    "        'padding': '10px',\n",
    "        'box-sizing': 'border-box',\n",
    "        'overflow-y': 'auto',\n",
    "        'max-width': '100%'\n",
    "    }\n",
    ")\n",
    "# Apply similar styling to output_box2\n",
    "output_box2 = pn.pane.Markdown(\n",
    "    width=None,\n",
    "    height=300,\n",
    "    styles={\n",
    "        'width': '100%',\n",
    "        'color': '#212529',\n",
    "        'background-color': '#f0f2f4',\n",
    "        'border': '1px solid #dee2e6',\n",
    "        'border-radius': '6px',\n",
    "        'font-size': '16px',\n",
    "        'font-weight': '400',\n",
    "        'font-family': 'Arial, sans-serif',\n",
    "        'line-height': '1.6',\n",
    "        'padding': '10px',\n",
    "        'box-sizing': 'border-box',\n",
    "        \n",
    "        # Text wrapping properties\n",
    "        'word-wrap': 'break-word',\n",
    "        'word-break': 'break-word',\n",
    "        'overflow-wrap': 'break-word',\n",
    "        'white-space': 'normal',\n",
    "        'text-align': 'left',\n",
    "        'hyphens': 'auto',\n",
    "        'overflow-y': 'auto',\n",
    "        \n",
    "        'display': 'block',\n",
    "        'max-width': '100%'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Time Output Boxes with more subtle styling\n",
    "output_box_retrievalTime = pn.pane.Markdown(\n",
    "    styles={\n",
    "        'color': '#666666',\n",
    "        'background-color': '#e9ecef',  # Consistent light gray background\n",
    "        'padding': '4px 8px',  # Slightly more padding\n",
    "        'border-radius': '4px',\n",
    "        'font-size': '12px',\n",
    "        'width': '100%',\n",
    "        'overflow': 'hidden',\n",
    "        'text-overflow': 'ellipsis',\n",
    "        'white-space': 'nowrap',\n",
    "        'border': '1px solid #ced4da',  #Subtle border\n",
    "        'font-family': 'Arial, sans-serif' \n",
    "    }\n",
    ")\n",
    "\n",
    "output_box_responseTime = pn.pane.Markdown(\n",
    "    styles={\n",
    "        'color': '#666666',\n",
    "        'background-color': '#e9ecef',  # Consistent light gray background\n",
    "        'padding': '4px 8px',  # Slightly more padding\n",
    "        'border-radius': '4px',\n",
    "        'font-size': '12px',\n",
    "        'width': '100%',\n",
    "        'overflow': 'hidden',\n",
    "        'text-overflow': 'ellipsis',\n",
    "        'white-space': 'nowrap',\n",
    "        'border': '1px solid #ced4da',  # Subtle border\n",
    "        'font-family': 'Arial, sans-serif'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Watch for changes in the input box value\n",
    "input_box.param.watch(lambda event: handle_input2(vectordb, embedding, llm, retriever), 'value')  # Pass arguments here\n",
    "#input_box.param.watch(handle_input_debounced, 'value')\n",
    "# Create a variable to track if it's the first run\n",
    "is_first_run = True\n",
    "if is_first_run:\n",
    "        # Call handle_input2()\n",
    "        handle_input2(vectordb, embedding, llm, retriever)\n",
    "        is_first_run = False\n",
    "\n",
    "\n",
    "# Create the dashboard layout with improved responsiveness\n",
    "dashboard_layout = pn.Column(\n",
    "    pn.Row(\n",
    "        pn.pane.Markdown(\n",
    "            \"# ChatGPT-like Conversation: RAG\", \n",
    "            styles={\n",
    "                'color': '#2c3e50',\n",
    "                'text-align': 'center',\n",
    "                'font-weight': 'bold',\n",
    "                'background-color': '#ecf0f1',\n",
    "                'padding': '5px',  # Reduced padding\n",
    "                'border-radius': '5px',\n",
    "                'width': '100%',\n",
    "                'margin-bottom': '5px',  # Reduced margin\n",
    "                'line-height': '1.2',  # Tighter line height\n",
    "                'font-size': '20px'  # Adjust font size if needed\n",
    "            }\n",
    "        ),\n",
    "        loading_indicator,\n",
    "        sizing_mode='stretch_width',\n",
    "        align='center',\n",
    "        height=50  # Set a fixed, smaller height\n",
    "    ),\n",
    "    \n",
    "    # Wrapper Row with explicit styling\n",
    "    pn.Row(\n",
    "        pn.Column(\n",
    "            input_box,\n",
    "            width_policy='max',\n",
    "            sizing_mode='stretch_width',\n",
    "            styles={\n",
    "                'flex': '1'  # 1/3 of the row\n",
    "            }\n",
    "        ),\n",
    "        pn.Column(\n",
    "            output_box,\n",
    "            width_policy='max',\n",
    "            sizing_mode='stretch_width',\n",
    "            styles={\n",
    "                'flex': '2'# 2/3 of the row\n",
    "                #'width': '100%', #\n",
    "                #'min-width': '0'  # #Ensures the column can shrink\n",
    "\n",
    "            }\n",
    "        ),\n",
    "        sizing_mode='stretch_width',\n",
    "        styles={\n",
    "            'gap': '2px',\n",
    "            'column-gap': '10px',\n",
    "            'width': '100%'  # Ensure full width of the row\n",
    "        }\n",
    "    ),\n",
    "    \n",
    "    # Compact Time Output Row\n",
    "    pn.Row(\n",
    "        pn.Column(\n",
    "            output_box_retrievalTime, \n",
    "            width_policy='max',\n",
    "            sizing_mode='stretch_width'\n",
    "        ), \n",
    "        pn.Column(\n",
    "            output_box_responseTime,\n",
    "            width_policy='max', \n",
    "            sizing_mode='stretch_width'\n",
    "        ),\n",
    "        sizing_mode='stretch_width',\n",
    "        styles={\n",
    "            'gap': '10px',  # Add gap between columns\n",
    "            'max-height': '40px',\n",
    "            'overflow': 'hidden',\n",
    "            'min-height': '60px',   # Increased minimum height\n",
    "            'max-height': '80px',   # Keep max height\n",
    "            'height': '60px',       # Explicit height\n",
    "        }\n",
    "    ),\n",
    "    # Additional Output Row\n",
    "    pn.Row(\n",
    "        output_box3,\n",
    "        sizing_mode='stretch_width'\n",
    "    ),    \n",
    "    # Additional Output Row\n",
    "    pn.Row(\n",
    "        output_box2,\n",
    "        sizing_mode='stretch_width'\n",
    "    ),\n",
    "    \n",
    "    # Global Column Styles\n",
    "    styles={\n",
    "        'background-color': '#f1f3f5',\n",
    "        'width': '100%',\n",
    "        'max-width': '100%',\n",
    "        'padding': '10px',\n",
    "        'gap': '10px'  # Add vertical gap between rows\n",
    "    },\n",
    "    sizing_mode='stretch_width'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Create a dashboard object using the layout\n",
    "dashboard = pn.panel(\n",
    "    dashboard_layout, \n",
    "    sizing_mode='stretch_both'  # Ensure dashboard itself stretches\n",
    ")\n",
    "\n",
    "# Display the dashboard in a new browser tab\n",
    "dashboard.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09696fb9-d8d4-4527-a538-2184ca3219bc",
   "metadata": {},
   "source": [
    "# Stop: Next similar but more genereal chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f8b717-2eda-49a2-92e1-3373fcd4fdd8",
   "metadata": {},
   "source": [
    "## 2nd Based on  client.chat.completions.create  : \n",
    "    * Browser TAB\n",
    "    * Prompt Input\n",
    "    * Query\n",
    "    * Response\n",
    "    * Whole message sent to Model\n",
    "## Chose Retrieval: Standard or Multi (langChain): line 32\n",
    " * overall the responses are quite slow, because of retrieval of useful text snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3811b2-7699-481c-a187-7260251acd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd\n",
    "import panel as pn\n",
    "from openai import OpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "#from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "import re\n",
    "import time\n",
    "\n",
    "\n",
    "# Define the template for the prompt\n",
    "template = \"\"\"\n",
    "Use the following context from the vector database and the previous conversation to answer the query. Incorporate your own knowledge and reasoning as an AI assistant:\n",
    "Previous Conversation: {history}\n",
    "Context: {context}\n",
    "Query: {query}\n",
    "Answer:\n",
    "{answer}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Create the prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"history\", \"context\", \"query\", \"answer\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "history = []\n",
    "\n",
    "# Point to the local OpenAI server\n",
    "client = OpenAI(base_url=\"http://localhost:1238/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "\n",
    "which_retriever='Multi'\n",
    "#which_retriever='Standard'\n",
    "\n",
    "if which_retriever =='Multi':\n",
    "    retriever=retriever_from_llm\n",
    "else:\n",
    "    # Set up the vector retriever\n",
    "    retriever = vectordb.as_retriever()\n",
    "\n",
    "    \n",
    "# Define a function to handle the user's input\n",
    "def handle_input2():\n",
    "    global is_first_run\n",
    "    wrap_width = 100\n",
    "\n",
    "    if is_first_run:\n",
    "        query = \"Hello, introduce yourself to someone opening this program for the first time. Be concise\"\n",
    "        is_first_run = False\n",
    "        some_context = \"\"\n",
    "    else:\n",
    "        output_box_retrievalTime.object = f\"Processing Retrieval {which_retriever}\"\n",
    "        output_box_gpt_responseTime = f\"Waiting for GPT\"\n",
    "        start_time = time.time()\n",
    "        query = input_box.value.strip()\n",
    "        search_results = retriever.get_relevant_documents(query)\n",
    "        #search_results = retriever_from_llm.get_relevant_documents(query)\n",
    "        some_context = \"\"\n",
    "        for result in search_results:\n",
    "            some_context += result.page_content + \"'Title-- '\"+result.metadata['Title']+\"--EndTitle | \\n\\n\"\n",
    "        \n",
    "        end_time = time.time()\n",
    "        # Calculate the elapsed time\n",
    "        elapsed_time = end_time - start_time\n",
    "        output_box_retrievalTime.object = f\"Time taken for Retrieval with: {elapsed_time:.2f} seconds\"\n",
    "    #history.append({\"role\": \"user\", \"content\": query)# + \" Database content: [\" + some_context + \"]\"})\n",
    "\n",
    "    if query:\n",
    "        # Generate the prompt using the template and input values\n",
    "        prompt = prompt_template.format(history=history, context=some_context, query=query, answer=\"\")\n",
    "        #prompt = prompt_template.format(history=history, answer=\"\")\n",
    "        output_box2.object=prompt\n",
    "        start_time = time.time()\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"LLMA/Meta-Llama-3-8B\",\n",
    "            messages=history + [{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.7,\n",
    "            stream=True,\n",
    "        )\n",
    "\n",
    "        \n",
    "        new_message = {\"role\": \"assistant\", \"content\": \"\"}\n",
    "\n",
    "        full_response = \"\"\n",
    "        for chunk in completion:\n",
    "            if chunk.choices[0].delta.content:\n",
    "                new_message[\"content\"] += chunk.choices[0].delta.content\n",
    "                full_response += (chunk.choices[0].delta.content)\n",
    "\n",
    "        formatted_text = f\"<pre style='white-space: pre-wrap; width: {wrap_width}ch; font-family: Arial, sans-serif; font-size: 12px;'>**Query:**\\n{query}\\n\\n**Final Answer:**\\n{full_response}</pre>\"\n",
    "        output_box.object = formatted_text\n",
    "\n",
    "        history.append(new_message)\n",
    "        \n",
    "        input_box.value = \"\"\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        output_box_responseTime.object = f\"Time taken for Model: {elapsed_time:.2f} seconds\"\n",
    "\n",
    "\n",
    "# Define a function to handle user input changes\n",
    "def handle_input_change(event):\n",
    "    handle_input2()\n",
    "\n",
    "# Load the Panel extension\n",
    "pn.extension()\n",
    "\n",
    "# Create an input box\n",
    "input_box = pn.widgets.TextAreaInput(width=400, height=100, styles={'overflow-y': 'scroll', 'text-align': 'center'})\n",
    "# Create the output box\n",
    "output_box = pn.pane.Markdown(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    styles={\n",
    "        'overflow-y': 'scroll',\n",
    "        'color': 'black',                   # Text color\n",
    "        'background-color': '#f0f0f0',      # Background color (light gray)\n",
    "        'font-size': '14px',                # Font size\n",
    "        'font-family': 'Courier New',       # Font family\n",
    "        'padding': '5px',                   # Padding inside the pane\n",
    "        'border': '1px solid red',          # Border around the pane\n",
    "        'text-align': 'center'              # Center the text\n",
    "    }\n",
    ")\n",
    "\n",
    "output_box2 = pn.pane.Markdown(\n",
    "    height=400,\n",
    "    styles={\n",
    "        'overflow-y': 'scroll',\n",
    "        'overflow-x': 'scroll',\n",
    "        'color': 'black',        # Text color\n",
    "        'background-color': '#f0f0f4',  # Background color\n",
    "        'font-size': '14px',     # Font size\n",
    "        'font-family': 'Courier New',  # Font family\n",
    "        'padding': '5px',        # Padding inside the pane\n",
    "        'border': '1px solid blue'  # Border around the pane\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "output_box_retrievalTime = pn.pane.Markdown()\n",
    "output_box_responseTime = pn.pane.Markdown()\n",
    "# Watch for changes in the input box value\n",
    "input_box.param.watch(handle_input_change, 'value')\n",
    "\n",
    "# Create a variable to track if it's the first run\n",
    "is_first_run = True\n",
    "if is_first_run:\n",
    "        # Call handle_input2()\n",
    "        handle_input2()\n",
    "        is_first_run = False\n",
    "\n",
    "         \n",
    "# Create the dashboard layout using Panel\n",
    "dashboard_layout = pn.Column(\n",
    "    pn.pane.Markdown(\"# ChatGPT-like Conversation: RAG\"),\n",
    "    pn.Spacer(height=20),\n",
    "    pn.Row(input_box, output_box),\n",
    "    pn.Row(pn.Spacer(height=20)),\n",
    "    pn.Row(output_box_retrievalTime, output_box_responseTime),\n",
    "    pn.Row(output_box2),\n",
    "    name=\"ChatGPT Dashboard\"\n",
    ")\n",
    "\n",
    "# Create a dashboard object using the layout\n",
    "dashboard = pn.panel(dashboard_layout)\n",
    "\n",
    "# Display the dashboard in a new browser tab\n",
    "dashboard.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073f50ae-1a12-4aae-aa90-7f5f947c971e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a3780-68d2-4fea-8fc5-e2984cdfd73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fccb34c-790d-493f-a74f-5b2a12ba55c9",
   "metadata": {},
   "source": [
    "# Alternative Version: based on QA CHAIN with BROWSER TAB - \n",
    " * output still not consitent and short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac895296-a285-4bbb-b26d-5ae9eebc19fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "import textwrap\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "# Create a RAG model\n",
    "llm = OpenAI(base_url=\"http://localhost:1238/v1\", api_key=\"lm-studio\")\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "# Define a custom prompt template\n",
    "template = \"\"\"\n",
    "Use the following context from the vector database and the previous conversation to answer the query. Incorporate your own knowledge and reasoning as an AI assistant:\n",
    "\n",
    "Previous Conversation: {history}\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"history\", \"context\", \"query\"], template=template)\n",
    "\n",
    "# Create a custom chain\n",
    "qa_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "\n",
    "# Load the Panel extension\n",
    "pn.extension()\n",
    "\n",
    "import textwrap\n",
    "import panel as pn\n",
    "# Create an input box\n",
    "input_box = pn.widgets.TextAreaInput()\n",
    "# Create the output box\n",
    "output_box = pn.pane.Markdown()\n",
    "# Create a history list to store the conversation\n",
    "history = []\n",
    "# Define a function to handle the user's input\n",
    "def handle_input():\n",
    "    query = input_box.value.strip()\n",
    "    if query:\n",
    "        # Add user input to the history\n",
    "        #history.append({\"role\": \"user\", \"content\": query})\n",
    "        # Process the query and generate a response\n",
    "        context = retriever.get_relevant_documents(query)\n",
    "        result_str = qa_chain.run(\n",
    "            history=\"\\n\".join([f\"{msg['role']}: {msg['content']}\" for msg in history]),\n",
    "            query=query,\n",
    "            #max_tokens=8096,\n",
    "            max_tokens=-1,\n",
    "            context=\"\".join([doc.page_content for doc in context])\n",
    "        )\n",
    "        final_answer_start = result_str.find(\"Final Answer:\")\n",
    "        if final_answer_start != -1:\n",
    "            final_answer = result_str[final_answer_start + len(\"Final Answer:\"):].strip()\n",
    "            output_box.object = f\"**Query:**\\n{query}\\n\\n**Final Answer:**\\n{textwrap.fill(final_answer, width=80)}\"\n",
    "        else:\n",
    "            final_answer=result_str\n",
    "            output_box.object = f\"**Query:**\\n{query}\\n\\n**Answer:**\\n{textwrap.fill(result_str, width=80)}\"\n",
    "        \n",
    "        # Add assistant response to the history\n",
    "        history.append({\"role\": \"assistant\", \"content\": final_answer})\n",
    "        history.append({\"role\": \"user\", \"content\": query})\n",
    "        # Clear the input box\n",
    "        input_box.value = \"\"\n",
    "        \n",
    "        \n",
    "# Watch for changes in the input box value\n",
    "input_box.param.watch(lambda event: handle_input(), 'value')\n",
    "# Create the dashboard layout using Panel\n",
    "dashboard_layout = pn.Column(\n",
    "    pn.pane.Markdown(\"# ChatGPT-like Conversation\"),\n",
    "    pn.Spacer(height=20),\n",
    "    pn.Row(input_box, output_box),\n",
    "    name=\"ChatGPT Dashboard\"\n",
    ")\n",
    "# Create a dashboard object using the layout\n",
    "dashboard = pn.panel(dashboard_layout)\n",
    "# Display the dashboard in a new browser tab\n",
    "dashboard.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9c0f4f-c064-4988-8e03-8d804d71717c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
