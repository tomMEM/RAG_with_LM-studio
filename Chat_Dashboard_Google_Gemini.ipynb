{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a84502f6-d41e-447c-b9e2-f2cd4d9958f1",
   "metadata": {},
   "source": [
    "# Google API GEMINI\n",
    " * config_API.json  with \n",
    "```text\n",
    "{\n",
    "  \"GEMINI_API_KEY\": \"Your Key\"\n",
    "} \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5bc975-72ca-4857-be3a-75963e50ef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using HTTP_PROXY: http://localhost:4321\n",
      "Using HTTPS_PROXY: http://localhost:4321\n",
      "Using NO_PROXY: localhost,127.0.0.1,0.0.0.0\n",
      "Google Gemini API configured successfully using config_API.json.\n",
      "Attempting to initialize model: gemini-1.5-flash-latest\n",
      "Successfully switched to model: gemini-1.5-flash-latest\n",
      "Launching Gradio app...\n",
      "Running on local URL:  http://0.0.0.0:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "# functional\n",
    "import os\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "import traceback\n",
    "import json # For loading config_API.json\n",
    "\n",
    "# --- Your Proxy Setup (for external calls like Google Gemini) ---\n",
    "PROXY_URL = os.environ.get(\"HTTP_PROXY_URL\", \"http://localhost:4321\")\n",
    "if PROXY_URL:\n",
    "    os.environ['http_proxy'] = PROXY_URL\n",
    "    os.environ['https_proxy'] = PROXY_URL\n",
    "    print(f\"Using HTTP_PROXY: {os.environ.get('http_proxy')}\")\n",
    "    print(f\"Using HTTPS_PROXY: {os.environ.get('https_proxy')}\")\n",
    "else:\n",
    "    print(\"No HTTP_PROXY_URL environment variable set, not using proxy for HTTP/HTTPS.\")\n",
    "\n",
    "# --- CRITICAL: Add NO_PROXY for local Gradio communication ---\n",
    "current_no_proxy = os.environ.get('NO_PROXY', '')\n",
    "additional_no_proxy_hosts = ['localhost', '127.0.0.1', '0.0.0.0']\n",
    "new_no_proxy_parts = [host for host in current_no_proxy.split(',') if host.strip()]\n",
    "for host in additional_no_proxy_hosts:\n",
    "    if host not in new_no_proxy_parts:\n",
    "        new_no_proxy_parts.append(host)\n",
    "os.environ['NO_PROXY'] = ','.join(new_no_proxy_parts)\n",
    "print(f\"Using NO_PROXY: {os.environ.get('NO_PROXY')}\")\n",
    "# --- END Proxy Setup ---\n",
    "\n",
    "# --- Global Variables ---\n",
    "model = None\n",
    "current_model_name = None\n",
    "genai_configured_successfully = False # Flag to check if genai.configure() was successful\n",
    "system_instruction = \"You are a helpful and friendly AI assistant. Be concise but informative.\"\n",
    "\n",
    "# --- Available Models ---\n",
    "AVAILABLE_MODELS = {\n",
    "    \"Gemini 1.5 Flash (Fast, Cost-Effective)\": \"gemini-1.5-flash-latest\",\n",
    "    \"Gemini 1.5 Pro (Most Capable)\": \"gemini-1.5-pro-latest\",\n",
    "    \"Gemini 1.0 Pro (General Purpose)\": \"gemini-1.0-pro\",\n",
    "}\n",
    "DEFAULT_MODEL_DISPLAY_NAME = \"Gemini 1.5 Flash (Fast, Cost-Effective)\"\n",
    "initial_model_technical_name = AVAILABLE_MODELS.get(DEFAULT_MODEL_DISPLAY_NAME, \"gemini-1.5-flash-latest\")\n",
    "\n",
    "\n",
    "# --- Configure Gemini API Key ---\n",
    "def configure_gemini_api():\n",
    "    global genai_configured_successfully\n",
    "    api_key_to_use = None\n",
    "    source = None\n",
    "\n",
    "    # 1. Try environment variable\n",
    "    env_api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "    if env_api_key:\n",
    "        api_key_to_use = env_api_key\n",
    "        source = \"environment variable\"\n",
    "    # 2. If not found, try config_API.json\n",
    "    elif os.path.exists('config_API.json'):\n",
    "        try:\n",
    "            with open('config_API.json', 'r') as f:\n",
    "                config = json.load(f)\n",
    "            file_api_key = config.get(\"GEMINI_API_KEY\")\n",
    "            if file_api_key:\n",
    "                api_key_to_use = file_api_key\n",
    "                source = \"config_API.json\"\n",
    "            else:\n",
    "                print(\"ERROR: GEMINI_API_KEY not found in config_API.json.\")\n",
    "        except (FileNotFoundError, json.JSONDecodeError) as e: # Should not happen due to os.path.exists but good practice\n",
    "            print(f\"Error loading or parsing config_API.json: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error reading config_API.json: {e}\")\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"ERROR: GEMINI_API_KEY environment variable not set and config_API.json not found.\")\n",
    "\n",
    "    if api_key_to_use:\n",
    "        try:\n",
    "            genai.configure(api_key=api_key_to_use)\n",
    "            genai_configured_successfully = True\n",
    "            print(f\"Google Gemini API configured successfully using {source}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Failed to configure Gemini API using key from {source}: {e}\")\n",
    "            traceback.print_exc()\n",
    "            genai_configured_successfully = False\n",
    "    else:\n",
    "        print(\"ERROR: No API key found to configure Google Gemini.\")\n",
    "        genai_configured_successfully = False\n",
    "\n",
    "configure_gemini_api() # Attempt to configure on script start\n",
    "\n",
    "\n",
    "# --- Initialize/Switch Gemini Model ---\n",
    "def initialize_gemini_model(model_name_to_load):\n",
    "    global model, current_model_name\n",
    "    if not genai_configured_successfully:\n",
    "        msg = \"Error: Gemini API not configured. Check API Key source (env var or config_API.json).\"\n",
    "        print(msg)\n",
    "        model = None\n",
    "        current_model_name = None\n",
    "        return msg\n",
    "\n",
    "    print(f\"Attempting to initialize model: {model_name_to_load}\")\n",
    "    try:\n",
    "        model = genai.GenerativeModel(\n",
    "            model_name=model_name_to_load,\n",
    "            system_instruction=system_instruction\n",
    "        )\n",
    "        current_model_name = model_name_to_load\n",
    "        success_msg = f\"Successfully switched to model: {current_model_name}\"\n",
    "        print(success_msg)\n",
    "        return success_msg\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error initializing model '{model_name_to_load}': {e}\"\n",
    "        print(error_msg)\n",
    "        traceback.print_exc()\n",
    "        model = None # Ensure model is None if initialization fails\n",
    "        current_model_name = None\n",
    "        return error_msg\n",
    "\n",
    "# --- Initialize with a default model on startup (if API was configured) ---\n",
    "if genai_configured_successfully:\n",
    "    initialize_gemini_model(initial_model_technical_name)\n",
    "else:\n",
    "    print(\"Skipping initial model load as Gemini API is not configured.\")\n",
    "\n",
    "\n",
    "def gemini_chat_responder(user_message, chat_history_gradio):\n",
    "    global model\n",
    "    if not genai_configured_successfully:\n",
    "         return (\"Error: Google Gemini API is not configured. \"\n",
    "                \"Please ensure GEMINI_API_KEY is set in your environment or in config_API.json.\")\n",
    "    if model is None:\n",
    "        return (\"Error: Google Gemini model is not initialized or failed to switch. \"\n",
    "                \"Please check API key, select a model from the dropdown, and see server logs.\")\n",
    "\n",
    "    if not user_message.strip():\n",
    "        return \"Please type a message.\"\n",
    "\n",
    "    gemini_history = []\n",
    "    for user_msg, ai_msg in chat_history_gradio:\n",
    "        if user_msg:\n",
    "            gemini_history.append({'role': 'user', 'parts': [{'text': user_msg}]})\n",
    "        if ai_msg:\n",
    "            gemini_history.append({'role': 'model', 'parts': [{'text': ai_msg}]})\n",
    "\n",
    "    gemini_history.append({'role': 'user', 'parts': [{'text': user_message}]})\n",
    "\n",
    "    try:\n",
    "        print(f\"Sending to Gemini ({model.model_name}): {gemini_history[-1]}\")\n",
    "        response = model.generate_content(\n",
    "            gemini_history,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                max_output_tokens=2048,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9,\n",
    "                top_k=40\n",
    "            ),\n",
    "        )\n",
    "        if not response.candidates:\n",
    "            block_reason = response.prompt_feedback.block_reason if response.prompt_feedback else \"Unknown\"\n",
    "            block_message = f\"The response was blocked. Reason: {block_reason}.\"\n",
    "            if response.prompt_feedback and response.prompt_feedback.safety_ratings:\n",
    "                block_message += f\" Safety ratings: {response.prompt_feedback.safety_ratings}\"\n",
    "            print(f\"Gemini Error: {block_message}\")\n",
    "            return f\"Error: {block_message} Please try rephrasing your message.\"\n",
    "\n",
    "        assistant_message = response.candidates[0].content.parts[0].text\n",
    "        print(f\"Received from Gemini: {assistant_message[:100]}...\")\n",
    "        return assistant_message\n",
    "    except genai.types.BlockedPromptError as e:\n",
    "        error_msg = f\"Gemini Error: Your prompt was blocked. {e}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "    except google.auth.exceptions.RefreshError as e:\n",
    "        error_msg = f\"Gemini Authentication Error: {e}. Please check your API key and ensure it's valid and has permissions.\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "    except google.api_core.exceptions.ResourceExhausted as e:\n",
    "        error_msg = f\"Gemini API Error: Rate limit exceeded or quota exhausted. {e}\"\n",
    "        print(error_msg)\n",
    "        return error_msg\n",
    "    except google.api_core.exceptions.GoogleAPIError as e:\n",
    "        error_msg = f\"Gemini API Error: {type(e).__name__} - {e}\"\n",
    "        print(error_msg)\n",
    "        traceback.print_exc()\n",
    "        return error_msg\n",
    "    except Exception as e:\n",
    "        error_msg = f\"An unexpected error occurred with Google Gemini: {type(e).__name__} - {str(e)}\"\n",
    "        print(error_msg)\n",
    "        traceback.print_exc()\n",
    "        return error_msg\n",
    "\n",
    "# --- Gradio UI with Blocks ---\n",
    "with gr.Blocks(theme=\"soft\", title=\"Gemini Chat Dashboard\") as demo:\n",
    "    gr.Markdown(\"# Google Gemini Chat Dashboard\")\n",
    "    gr.Markdown(\"Chat with an AI assistant powered by Google Gemini. Select your desired model below.\")\n",
    "\n",
    "    with gr.Row():\n",
    "        model_dropdown = gr.Dropdown(\n",
    "            choices=list(AVAILABLE_MODELS.keys()),\n",
    "            value=DEFAULT_MODEL_DISPLAY_NAME,\n",
    "            label=\"Select LLM Model\",\n",
    "            interactive=True # Will be set to False if API not configured\n",
    "        )\n",
    "        model_status_text = gr.Textbox(\n",
    "            label=\"Model Status\",\n",
    "            value=(f\"Current model: {current_model_name}\" if current_model_name else \"API Not Configured or Model Not Initialized\"),\n",
    "            interactive=False,\n",
    "            max_lines=1\n",
    "        )\n",
    "\n",
    "    # The ChatInterface itself, embedded in Blocks\n",
    "    chat_interface = gr.ChatInterface(\n",
    "        fn=gemini_chat_responder,\n",
    "        chatbot=gr.Chatbot(height=500, label=\"Conversation\", show_copy_button=True, avatar_images=(\"user.png\", \"bot.png\")),\n",
    "        textbox=gr.Textbox(placeholder=\"Type your message here and press Enter...\", lines=3, label=\"Your Message\"),\n",
    "        examples=[\n",
    "            \"Hello, how are you today?\",\n",
    "            \"What's the capital of France?\",\n",
    "            \"Write a short poem about a curious cat.\"\n",
    "        ],\n",
    "        retry_btn=\"Retry\",\n",
    "        undo_btn=\"Undo Last Turn\",\n",
    "        clear_btn=\"Clear Conversation\",\n",
    "    )\n",
    "\n",
    "    # --- Event Handler for Dropdown Change ---\n",
    "    def handle_model_change(selected_display_name):\n",
    "        if not genai_configured_successfully:\n",
    "            return \"Cannot change model: Gemini API not configured.\"\n",
    "        technical_name = AVAILABLE_MODELS.get(selected_display_name)\n",
    "        if technical_name:\n",
    "            feedback_message = initialize_gemini_model(technical_name)\n",
    "            return feedback_message\n",
    "        return \"Error: Selected model name not found in configuration.\"\n",
    "\n",
    "    model_dropdown.change(\n",
    "        fn=handle_model_change,\n",
    "        inputs=[model_dropdown],\n",
    "        outputs=[model_status_text]\n",
    "    )\n",
    "\n",
    "    # If API is not configured, disable the dropdown and update status\n",
    "    if not genai_configured_successfully:\n",
    "        model_dropdown.interactive = False # This doesn't work directly after Blocks creation\n",
    "                                            # Need to update properties dynamically or handle it in the UI logic\n",
    "        gr.Markdown(\"### <p style='color:red;'>API Key Not Configured. Chat functionality will be disabled.</p>\")\n",
    "        # A more Gradio-idiomatic way to update interactivity is through an event,\n",
    "        # but for initial setup, this print and the checks in responders are key.\n",
    "        # You could also update the model_status_text and model_dropdown.interactive\n",
    "        # using a dummy gr.Button.click() event that fires on load, but that's more complex.\n",
    "        # The current checks in `gemini_chat_responder` and `handle_model_change`\n",
    "        # will prevent operations if `genai_configured_successfully` is False.\n",
    "        # The `model_status_text.value` is also set appropriately at the start.\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Launching Gradio app...\")\n",
    "    if not genai_configured_successfully:\n",
    "        print(\"\\nWARNING: Google Gemini API key not found or configuration failed.\")\n",
    "        print(\"The Gradio interface will launch, but chat functionality will be impaired until the API is configured and a model is loaded.\\n\")\n",
    "    elif model is None: # API configured, but initial model load failed\n",
    "        print(\"\\nWARNING: Google Gemini API configured, but initial model failed to load.\")\n",
    "        print(\"Chat functionality may be impaired. Check logs and try selecting a model from the dropdown.\\n\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        demo.launch(server_name=\"0.0.0.0\", debug=True, share=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to launch Gradio interface: {e}\")\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allensdk",
   "language": "python",
   "name": "allensdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
